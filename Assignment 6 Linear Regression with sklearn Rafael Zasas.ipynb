{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "For each of the Theta vectors below, find the decision boundary, and give an example of a point that would get classified as Class 0 and a point that would get classified as Class 1. (There isn't really any Python coding to do here, so you can just type your answers below.)\n",
    "<ol>\n",
    "    <li> $\\theta =[5,-2]$ </li> \n",
    "     <li> $\\theta =[5,-2,3]$ </li> \n",
    "     <li> $\\theta =[5,-2,3,-4]$ </li> \n",
    "     <li> $\\theta =[5,-2,3,-4,1]$ </li> \n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " 1) $$ x_1 = \\frac{5}{2} $$ <br> Anything < $$\\frac{3}{2}$$ is 0 and anything > than is 1 <br>\n",
    " 2) $$ x_1 = \\frac{3}{2}x_2 + \\frac{5}{2} $$ <br> $$(0,3)$$ would be 1 and $$(0,0)$$ would be 0<br>\n",
    " 3) $$ x_1 = \\frac{3}{2}x_2 - 2x_3 + \\frac{5}{2}$$ <br> $$(0,0,0)$$ will be 0 and $$(-3,2,4)$$ will be 1 <br>\n",
    " 4) $$ x_1 = \\frac{3}{2}x_2 - 2x_3 -\\frac{1}{2}x_4+ \\frac{5}{2} $$ <br> $$(0,0,0,0)$$ will be 0 and $$(,,,)$$ will be a 1<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Compare the three different methods of Scaling/Normalizing data from sklearn on the given $X$ vector. Explain what each technique is doing to normalize the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(10, 1)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## This cell is just set up.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X=np.array([1.0,5,-2,4,-6,7,2,-8,9,0])\n",
    "X=X.reshape(-1,1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[-0.03880753]\n",
      " [ 0.737343  ]\n",
      " [-0.62092042]\n",
      " [ 0.54330537]\n",
      " [-1.39707095]\n",
      " [ 1.12541826]\n",
      " [ 0.15523011]\n",
      " [-1.78514621]\n",
      " [ 1.51349353]\n",
      " [-0.23284516]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## Example for first method = StandardScaler\n",
    "scaler1=StandardScaler()\n",
    "Xss=scaler1.fit(X)\n",
    "scaler1.transform(X)\n",
    "\n",
    "print(scaler1.transform(X))\n",
    "StandardScaler??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A) What does StandardScaler do? \n",
    "\n",
    "Standard Scalar standardizes the features by removing the mean and scaling to unit vectors\n",
    "\n",
    "standard score of sample x is calculated using <br>\n",
    "\n",
    "$$ z = (x-u) / s $$  <br>\n",
    "where u is the mean of the training samples and s is the standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) Explain what the following code is doing and why it is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[1.2]\n",
      "[5.15363949]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(scaler1.mean_) # this returns the mean value for each feature in the data.\n",
    "print(scaler1.scale_)  # returns the feature relative scaling of the data\n",
    "\n",
    "# these are used when transforming the data back when the fit is done and the data needs to be visualised \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C)  Repeat (A) and (B) as above for MinMaxScaler in place of StandardScaler and explain what \n",
    "that method is doing. You'll need to think about what the appropriate parameters are for MinMaxScaler for (B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[0.47058824]\n",
      "[0.05882353]\n",
      "[17.]\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## Example for second method = MinMaxScalar\n",
    "MinMaxScaler??\n",
    "scaler2=MinMaxScaler()  # leaving default parameters to specify data in range of 0-1 \n",
    "Xmm=scaler2.fit(X)\n",
    "scaler2.transform(X)\n",
    "\n",
    "\n",
    "\n",
    "# (B) Explain what the following code is doing and why it is important.\n",
    "print(scaler2.min_)  # returns per feature adjustment for minimum \n",
    "print(scaler2.scale_)  # per feature relative scaling of the data \n",
    "print(scaler2.data_range_)  # per feature range seen in the data\n",
    "print(Xmm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "(A) What does MinMaxScalar do? \n",
    "\n",
    "MinMaxScalar transforms the features by scaling each feature to a given range and is given by <br>\n",
    "\n",
    "$$ X_{std} = \\frac{(X - X_{min})} {X_{max}} - X_{min} $$\n",
    "\n",
    "$$ X_{scaled} = X_{std} * (max - min) + min $$\n",
    "\n",
    "Min Max Scalar takes arguments of a tuple which specifies the desired range of transformed data. default is (0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Use sklearn to redo your linear regression from HW due Jan 27, Question 3. That is:\n",
    "<br>\n",
    "(A) Create an X which contains only the features you used before.\n",
    "<br>\n",
    "(B) Drop NaNs and Normalize the data. (Use one of the sklearn functions to do the Normalization now.)\n",
    "<br>\n",
    "(C) Perform the Linear Regression using sklearn commands and output your $\\theta$ vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       Life expectancy   Adult Mortality  Infant deaths      Alcohol  \\\ncount       2928.000000      2928.000000    2938.000000  2744.000000   \nmean          69.224932       164.796448      30.303948     4.602861   \nstd            9.523867       124.292079     117.926501     4.052413   \nmin           36.300000         1.000000       0.000000     0.010000   \n25%           63.100000        74.000000       0.000000     0.877500   \n50%           72.100000       144.000000       3.000000     3.755000   \n75%           75.700000       228.000000      22.000000     7.702500   \nmax           89.000000       723.000000    1800.000000    17.870000   \n\n       percentage expenditure  Hepatitis B       Measles           BMI  \\\ncount             2938.000000  2385.000000    2938.000000  2904.000000   \nmean               738.251295    80.940461    2419.592240    38.321247   \nstd               1987.914858    25.070016   11467.272489    20.044034   \nmin                  0.000000     1.000000       0.000000     1.000000   \n25%                  4.685343    77.000000       0.000000    19.300000   \n50%                 64.912906    92.000000      17.000000    43.500000   \n75%                441.534144    97.000000     360.250000    56.200000   \nmax              19479.911610    99.000000  212183.000000    87.300000   \n\n       under-five deaths         Polio  Total expenditure  Diphtheria   \\\ncount         2938.000000  2919.000000         2712.00000  2919.000000   \nmean            42.035739    82.550188            5.93819    82.324084   \nstd            160.445548    23.428046            2.49832    23.716912   \nmin              0.000000     3.000000            0.37000     2.000000   \n25%              0.000000    78.000000            4.26000    78.000000   \n50%              4.000000    93.000000            5.75500    93.000000   \n75%             28.000000    97.000000            7.49250    97.000000   \nmax           2500.000000    99.000000           17.60000    99.000000   \n\n          HIV/AIDS            GDP    Population  thinness  1-19 years  \\\ncount  2938.000000    2490.000000  2.286000e+03           2904.000000   \nmean      1.742103    7483.158469  1.275338e+07              4.839704   \nstd       5.077785   14270.169342  6.101210e+07              4.420195   \nmin       0.100000       1.681350  3.400000e+01              0.100000   \n25%       0.100000     463.935626  1.957932e+05              1.600000   \n50%       0.100000    1766.947595  1.386542e+06              3.300000   \n75%       0.800000    5910.806335  7.420359e+06              7.200000   \nmax      50.600000  119172.741800  1.293859e+09             27.700000   \n\n       thinness 5-9 years  Income composition of resources    Schooling  \ncount         2904.000000                      2771.000000  2775.000000  \nmean             4.870317                         0.627551    11.992793  \nstd              4.508882                         0.210904     3.358920  \nmin              0.100000                         0.000000     0.000000  \n25%              1.500000                         0.493000    10.100000  \n50%              3.300000                         0.677000    12.300000  \n75%              7.200000                         0.779000    14.300000  \nmax             28.600000                         0.948000    20.700000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Life expectancy</th>\n      <th>Adult Mortality</th>\n      <th>Infant deaths</th>\n      <th>Alcohol</th>\n      <th>percentage expenditure</th>\n      <th>Hepatitis B</th>\n      <th>Measles</th>\n      <th>BMI</th>\n      <th>under-five deaths</th>\n      <th>Polio</th>\n      <th>Total expenditure</th>\n      <th>Diphtheria</th>\n      <th>HIV/AIDS</th>\n      <th>GDP</th>\n      <th>Population</th>\n      <th>thinness  1-19 years</th>\n      <th>thinness 5-9 years</th>\n      <th>Income composition of resources</th>\n      <th>Schooling</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2928.000000</td>\n      <td>2928.000000</td>\n      <td>2938.000000</td>\n      <td>2744.000000</td>\n      <td>2938.000000</td>\n      <td>2385.000000</td>\n      <td>2938.000000</td>\n      <td>2904.000000</td>\n      <td>2938.000000</td>\n      <td>2919.000000</td>\n      <td>2712.00000</td>\n      <td>2919.000000</td>\n      <td>2938.000000</td>\n      <td>2490.000000</td>\n      <td>2.286000e+03</td>\n      <td>2904.000000</td>\n      <td>2904.000000</td>\n      <td>2771.000000</td>\n      <td>2775.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>69.224932</td>\n      <td>164.796448</td>\n      <td>30.303948</td>\n      <td>4.602861</td>\n      <td>738.251295</td>\n      <td>80.940461</td>\n      <td>2419.592240</td>\n      <td>38.321247</td>\n      <td>42.035739</td>\n      <td>82.550188</td>\n      <td>5.93819</td>\n      <td>82.324084</td>\n      <td>1.742103</td>\n      <td>7483.158469</td>\n      <td>1.275338e+07</td>\n      <td>4.839704</td>\n      <td>4.870317</td>\n      <td>0.627551</td>\n      <td>11.992793</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.523867</td>\n      <td>124.292079</td>\n      <td>117.926501</td>\n      <td>4.052413</td>\n      <td>1987.914858</td>\n      <td>25.070016</td>\n      <td>11467.272489</td>\n      <td>20.044034</td>\n      <td>160.445548</td>\n      <td>23.428046</td>\n      <td>2.49832</td>\n      <td>23.716912</td>\n      <td>5.077785</td>\n      <td>14270.169342</td>\n      <td>6.101210e+07</td>\n      <td>4.420195</td>\n      <td>4.508882</td>\n      <td>0.210904</td>\n      <td>3.358920</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>36.300000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.010000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>0.37000</td>\n      <td>2.000000</td>\n      <td>0.100000</td>\n      <td>1.681350</td>\n      <td>3.400000e+01</td>\n      <td>0.100000</td>\n      <td>0.100000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>63.100000</td>\n      <td>74.000000</td>\n      <td>0.000000</td>\n      <td>0.877500</td>\n      <td>4.685343</td>\n      <td>77.000000</td>\n      <td>0.000000</td>\n      <td>19.300000</td>\n      <td>0.000000</td>\n      <td>78.000000</td>\n      <td>4.26000</td>\n      <td>78.000000</td>\n      <td>0.100000</td>\n      <td>463.935626</td>\n      <td>1.957932e+05</td>\n      <td>1.600000</td>\n      <td>1.500000</td>\n      <td>0.493000</td>\n      <td>10.100000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>72.100000</td>\n      <td>144.000000</td>\n      <td>3.000000</td>\n      <td>3.755000</td>\n      <td>64.912906</td>\n      <td>92.000000</td>\n      <td>17.000000</td>\n      <td>43.500000</td>\n      <td>4.000000</td>\n      <td>93.000000</td>\n      <td>5.75500</td>\n      <td>93.000000</td>\n      <td>0.100000</td>\n      <td>1766.947595</td>\n      <td>1.386542e+06</td>\n      <td>3.300000</td>\n      <td>3.300000</td>\n      <td>0.677000</td>\n      <td>12.300000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>75.700000</td>\n      <td>228.000000</td>\n      <td>22.000000</td>\n      <td>7.702500</td>\n      <td>441.534144</td>\n      <td>97.000000</td>\n      <td>360.250000</td>\n      <td>56.200000</td>\n      <td>28.000000</td>\n      <td>97.000000</td>\n      <td>7.49250</td>\n      <td>97.000000</td>\n      <td>0.800000</td>\n      <td>5910.806335</td>\n      <td>7.420359e+06</td>\n      <td>7.200000</td>\n      <td>7.200000</td>\n      <td>0.779000</td>\n      <td>14.300000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>89.000000</td>\n      <td>723.000000</td>\n      <td>1800.000000</td>\n      <td>17.870000</td>\n      <td>19479.911610</td>\n      <td>99.000000</td>\n      <td>212183.000000</td>\n      <td>87.300000</td>\n      <td>2500.000000</td>\n      <td>99.000000</td>\n      <td>17.60000</td>\n      <td>99.000000</td>\n      <td>50.600000</td>\n      <td>119172.741800</td>\n      <td>1.293859e+09</td>\n      <td>27.700000</td>\n      <td>28.600000</td>\n      <td>0.948000</td>\n      <td>20.700000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 262
    }
   ],
   "source": [
    "# Here's data that you used before.\n",
    "import pandas as pd\n",
    "URL = 'http://facweb1.redlands.edu/fac/joanna_bieri/machinelearning/LifeExpectancyData.csv'\n",
    "df = pd.read_csv(URL)\n",
    "df.drop('Country', axis=1, inplace=True)\n",
    "df.drop('Year', axis=1, inplace=True)\n",
    "df.drop('Status', axis=1, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Transformed (normalized) df:\n",
      "[[0.36288089 0.         0.50527426 0.48792271]\n",
      " [0.37396122 0.         0.5021097  0.48309179]\n",
      " [0.36980609 0.         0.49578059 0.47826087]\n",
      " [0.37534626 0.         0.48839662 0.47342995]\n",
      " [0.37950139 0.         0.47890295 0.4589372 ]]\n",
      "\n",
      "Bottom 5 of X matrix:\n",
      "[[1.         0.66336634 0.42932489 0.44444444]\n",
      " [0.98891967 0.72475248 0.44092827 0.4589372 ]\n",
      " [0.09972299 0.78613861 0.45042194 0.48309179]\n",
      " [0.94875346 0.83168317 0.45042194 0.47342995]\n",
      " [0.91966759 0.85940594 0.45780591 0.47342995]]\n",
      "\n",
      "Shape of X matrix : (2768, 4)\n",
      "\n",
      "Shape of y vector: (2768,)\n",
      "\n",
      "y vector:\n",
      "0       65.0\n",
      "1       59.9\n",
      "2       59.9\n",
      "3       59.5\n",
      "4       59.2\n",
      "        ... \n",
      "2933    44.3\n",
      "2934    44.5\n",
      "2935    44.8\n",
      "2936    45.3\n",
      "2937    46.0\n",
      "Name: Life expectancy , Length: 2768, dtype: float64\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Select just the features you used and the target output in x and y\n",
    "\n",
    "\n",
    "''' have to drop unnecessary columns with y vec included to ensure the same dimensions after dropping NAs  '''\n",
    "\n",
    "df.drop(\n",
    "  ['Infant deaths',\n",
    " 'Alcohol',\n",
    " 'percentage expenditure',\n",
    " 'Hepatitis B',\n",
    " 'Measles ',\n",
    " 'BMI',\n",
    " 'under-five deaths ',\n",
    " 'Polio',\n",
    " 'Total expenditure',\n",
    " 'Diphtheria ',\n",
    " 'GDP',\n",
    " 'Population',\n",
    " 'thinness  1-19 years',\n",
    " 'thinness 5-9 years',], axis=1, inplace=True) # drops the unwanted features as well as strings \n",
    "\n",
    "df.dropna(inplace=True) # have to drop NA's for the X matrix and Y vec together \n",
    "\n",
    "y = df['Life expectancy ']  # keep y vec as a series. Not reshaping into col vec\n",
    "df.drop('Life expectancy ', axis=1, inplace=True)  # now remove y vec from the x matrix \n",
    "\n",
    "# Normalize the data \n",
    "scalar=MinMaxScaler()\n",
    "Xmm=scalar.fit(df)  # Do i need to be saving this in a variable\n",
    "\n",
    "X=scalar.transform(df) # normalized feature set\n",
    "print(f'Transformed (normalized) df:\\n{X[:5]}\\n')\n",
    "print(f'Bottom 5 of X matrix:\\n{X[-5:]}\\n')\n",
    "# Check the shape of your normalized data\n",
    "print(f'Shape of X matrix : {X.shape}\\n')\n",
    "print(f'Shape of y vector: {y.shape}\\n')\n",
    "\n",
    "print(f'y vector:\\n{y}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 264
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()  # create an object that's easier to work with \n",
    "lm.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Theta 0, ie. Intercept: 53.82224617163827\n",
      "\n",
      "Remaining Thetas, 1 through f: [-13.80107829 -26.15037411   9.23591552  23.06757498]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## This is theta_0\n",
    "print(f'Theta 0, ie. Intercept: {lm.intercept_}\\n')\n",
    " \n",
    "print(f'Remaining Thetas, 1 through f: {lm.coef_ }')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 \n",
    "Repeat the above but use the other normalization technique from above. How did the theta parameters change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Transformed (normalized) df:\n",
      "[[ 0.81311838 -0.32018438 -0.70360648 -0.5677621 ]\n",
      " [ 0.87819489 -0.32018438 -0.71782854 -0.59765   ]\n",
      " [ 0.8537912  -0.32018438 -0.74627265 -0.62753789]\n",
      " [ 0.88632945 -0.32018438 -0.77945746 -0.65742579]\n",
      " [ 0.91073314 -0.32018438 -0.82212363 -0.74708949]]\n",
      "\n",
      "Bottom 5 of X matrix:\n",
      "[[ 4.55501757  6.13838804 -1.04493586 -0.83675319]\n",
      " [ 4.48994106  6.73604698 -0.99278831 -0.74708949]\n",
      " [-0.73244867  7.33370592 -0.95012214 -0.59765   ]\n",
      " [ 4.25403872  7.7771303  -0.95012214 -0.65742579]\n",
      " [ 4.08321289  8.04704079 -0.91693734 -0.65742579]]\n",
      "\n",
      "Shape of X matrix : (2768, 4)\n",
      "\n",
      "Shape of y vector: (2768,)\n",
      "\n",
      "y vector:\n",
      "0       65.0\n",
      "1       59.9\n",
      "2       59.9\n",
      "3       59.5\n",
      "4       59.2\n",
      "        ... \n",
      "2933    44.3\n",
      "2934    44.5\n",
      "2935    44.8\n",
      "2936    45.3\n",
      "2937    46.0\n",
      "Name: Life expectancy , Length: 2768, dtype: float64\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Using Standard Scalar for normalization\n",
    "\n",
    "# Normalize the data \n",
    "std_scalar=StandardScaler()\n",
    "Xmm=std_scalar.fit(df)\n",
    "print(Xmm)\n",
    "X=std_scalar.transform(df) # normalized feature set\n",
    "print(f'Transformed (normalized) df:\\n{X[:5]}\\n')\n",
    "print(f'Bottom 5 of X matrix:\\n{X[-5:]}\\n')\n",
    "# Check the shape of your normalized data\n",
    "print(f'Shape of X matrix : {X.shape}\\n')\n",
    "print(f'Shape of y vector: {y.shape}\\n')\n",
    "\n",
    "print(f'y vector:\\n{y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Theta 0, ie. Intercept: 69.34956647398845\n",
      "\n",
      "Remaining Thetas, 1 through f: [-2.34985774 -2.68593069  2.05508811  3.72851774]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lm.fit(X,y)\n",
    "## This is theta_0\n",
    "print(f'Theta 0, ie. Intercept: {lm.intercept_}\\n')\n",
    " \n",
    "print(f'Remaining Thetas, 1 through f: {lm.coef_ }')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Repeat the above but do not normalize the data before calling the LinearRegression() function. Instead call the LinearRegression() function with \n",
    "lm = LinearRegression(normalize=True). How did the theta parameters change? What is this doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "'''Using the same data as before but normalizing it with the built in normalization in linear regression from sklearn'''\n",
    "\n",
    "df = pd.read_csv(URL)\n",
    "df.drop('Country', axis=1, inplace=True)\n",
    "df.drop('Year', axis=1, inplace=True)\n",
    "df.drop('Status', axis=1, inplace=True)\n",
    "df.describe()\n",
    "\n",
    "''' have to drop unnecessary columns with y vec included to ensure the same dimensions after dropping NAs  '''\n",
    "\n",
    "df.drop(\n",
    "  ['Infant deaths',\n",
    " 'Alcohol',\n",
    " 'percentage expenditure',\n",
    " 'Hepatitis B',\n",
    " 'Measles ',\n",
    " 'BMI',\n",
    " 'under-five deaths ',\n",
    " 'Polio',\n",
    " 'Total expenditure',\n",
    " 'Diphtheria ',\n",
    " 'GDP',\n",
    " 'Population',\n",
    " 'thinness  1-19 years',\n",
    " 'thinness 5-9 years',], axis=1, inplace=True) # drops the unwanted features as well as strings \n",
    "\n",
    "df.dropna(inplace=True) # have to drop NA's for the X matrix and Y vec together \n",
    "\n",
    "y = df['Life expectancy ']  # keep y vec as a series. Not reshaping into col vec\n",
    "df.drop('Life expectancy ', axis=1, inplace=True)  # now remove y vec from the x matrix \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Theta 0, ie. Intercept: 53.893144157550296\n",
      "\n",
      "Remaining Thetas, 1 through f: [-0.01911507 -0.51782919  9.74252692  1.1143756 ]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lm = LinearRegression(normalize=True)\n",
    "lm.fit(df,y)\n",
    "\n",
    "## This is theta_0\n",
    "print(f'Theta 0, ie. Intercept: {lm.intercept_}\\n')\n",
    " \n",
    "print(f'Remaining Thetas, 1 through f: {lm.coef_ }')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "For your favorite normalization technique, pick a different set of 3-5 features and see how the theta parameters change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Index(['Life expectancy ', 'Infant deaths', 'Hepatitis B', 'Measles ',\n",
      "       'thinness 5-9 years'],\n",
      "      dtype='object')\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "'''Using the same data as before but normalizing it with the built in normalization in linear regression from sklearn'''\n",
    "\n",
    "df = pd.read_csv(URL)\n",
    "df.drop('Country', axis=1, inplace=True)\n",
    "df.drop('Year', axis=1, inplace=True)\n",
    "df.drop('Status', axis=1, inplace=True)\n",
    "df.describe()\n",
    "''' have to drop unnecessary columns with y vec included to ensure the same dimensions after dropping NAs  '''\n",
    "\n",
    "df.drop(\n",
    "  [ \n",
    "   'Adult Mortality',\n",
    "   'Alcohol',\n",
    "   'percentage expenditure',\n",
    "   'BMI',\n",
    "   'under-five deaths ',\n",
    "   'Polio',\n",
    "   'Total expenditure',\n",
    "   'Diphtheria ',\n",
    "   'HIV/AIDS',\n",
    "   'GDP',\n",
    "   'Population',\n",
    "   'thinness  1-19 years',\n",
    "   'Income composition of resources',\n",
    "   'Schooling'], axis=1, inplace=True) # drops the unwanted features as well as strings \n",
    "'''Keeping: Measles, Hepatitis B, Infant deaths, thinness 5-9 years '''\n",
    "df.dropna(inplace=True) # have to drop NA's for the X matrix and Y vec together \n",
    "\n",
    "y = df['Life expectancy ']  # keep y vec as a series. Not reshaping into col vec\n",
    "df.drop('Life expectancy ', axis=1, inplace=True)  # now remove y vec from the x matrix \n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Theta 0, ie. Intercept: 68.24375481302054\n",
      "\n",
      "Remaining Thetas, 1 through f: [ 4.68246988e-03  7.09097110e-02 -2.40303209e-05 -8.48337112e-01]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "''' Using existing lm object but changing the fit to the new data.'''\n",
    "lm.fit(df,y)\n",
    "\n",
    "## This is theta_0\n",
    "print(f'Theta 0, ie. Intercept: {lm.intercept_}\\n')\n",
    " \n",
    "print(f'Remaining Thetas, 1 through f: {lm.coef_ }')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
